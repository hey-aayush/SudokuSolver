{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Digit_classification .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5j-vjSQyTFZb",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlnwKxKlyjVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d183101-8953-4874-ea38-398f55f6de23"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdTJvBrNkEcV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "842ac49d-1300-4692-ae0d-d1190a6b9bcd"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)= mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dWlfN1uxTN5s",
        "colab": {}
      },
      "source": [
        "images=[]\n",
        "labels=[]\n",
        "X_train=[]\n",
        "Y_train=[]\n",
        "X_test=[]\n",
        "Y_test=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnKBs-wtrEJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size=(28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QiFQBuBso8Hp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cddf8dee-0468-4520-b54f-36b152055d1b"
      },
      "source": [
        "# load numpy array from npy file\n",
        "from numpy import load\n",
        "# load array\n",
        "loaded_image_data = load('/content/drive/My Drive/Data_soduku/Final_Data/Processed_images20.npy')\n",
        "loaded_label_data = load('/content/drive/My Drive/Data_soduku/Final_Data/Processed_labels20.npy')\n",
        "# print the array\n",
        "print(loaded_image_data.shape)\n",
        "print(loaded_label_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(140693, 28, 28)\n",
            "(140693,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jYWLETpHT2ln",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(loaded_image_data, loaded_label_data, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "erYJ4xrzT7J3",
        "colab": {}
      },
      "source": [
        "X_train=np.array(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lGVEVliLT9oR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c54f022a-d18c-41e8-8e1d-bd06e7a346e2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119589, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qmcVd-WFT_BH",
        "colab": {}
      },
      "source": [
        "Y_test=np.array(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rgEbWkdVUBOQ",
        "colab": {}
      },
      "source": [
        "Y_train=np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8FR2DKxUEbC",
        "colab": {}
      },
      "source": [
        "Y_train=np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lduQ4RsLUGKy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcdbfd1b-d092-415c-84b1-aae359cd50ff"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119589,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJWOnf3oUIZ-",
        "colab": {}
      },
      "source": [
        "combined = list(zip(X_train, Y_train))\n",
        "\n",
        "random.shuffle(combined)\n",
        "\n",
        "X_train, Y_train = zip(*combined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lj8giZ4aUKJm",
        "colab": {}
      },
      "source": [
        "combined = list(zip(X_test, Y_test))\n",
        "\n",
        "random.shuffle(combined)\n",
        "\n",
        "X_test, Y_test = zip(*combined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gzBWjiu_UL8z",
        "colab": {}
      },
      "source": [
        "X_train=np.array(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LEpSfp-mURGe",
        "colab": {}
      },
      "source": [
        "Y_train=np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vYNvhKR-USXl",
        "colab": {}
      },
      "source": [
        "X_test=np.array(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VTB89N2gUTv3",
        "colab": {}
      },
      "source": [
        "Y_test=np.array(Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ynMEksZ_UVKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad0ccd2d-05f4-47b0-f307-baa836f10b51"
      },
      "source": [
        "(X_train).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(119589, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzXoIV_yCHBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ac2feae-f870-4cb8-b2ff-75f6c0051ce9"
      },
      "source": [
        "X_train[900].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6TQjmkSGUWmN",
        "colab": {}
      },
      "source": [
        "X_train=X_train/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9w-DbSaXUYxc",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(119589,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gq2NGOTnUZ_f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4978398-800c-437b-81d0-89badf264aa3"
      },
      "source": [
        "(X_test).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21104, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QDsxTRG0UbmT",
        "colab": {}
      },
      "source": [
        "X_test=X_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l5RTngYTUdTg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bb688a8-53bc-471e-fe66-68786e58c659"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21104, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rijASU32UfLL",
        "colab": {}
      },
      "source": [
        "X_test = X_test.reshape(21104,28,28,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kp2e_pjtUg1-",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qSZEuMAoUipQ",
        "colab": {}
      },
      "source": [
        "Y_cat_train = to_categorical(Y_train,num_classes=10)\n",
        "Y_cat_test = to_categorical(Y_test,num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eGkGNRKVUkBT",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L-LEvGxCUlbv",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s2IweMKLUnYJ",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KHCIM_aIUp2j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "30b1c5a3-7715-4efe-d044-ba5a960b953a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fh8xBmB-Ur09",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "btZ1A2hYUu9a",
        "colab": {}
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss',patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GRbrpe-fUwQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d92e05f0-6b87-46ad-8038-b95053b13977"
      },
      "source": [
        "model.fit(X_train,Y_cat_train,epochs=1000,validation_data=(X_test,Y_cat_test),callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 2.2726 - accuracy: 0.1833 - val_loss: 2.2127 - val_accuracy: 0.4146\n",
            "Epoch 2/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 2.1662 - accuracy: 0.3124 - val_loss: 2.0665 - val_accuracy: 0.5638\n",
            "Epoch 3/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 2.0188 - accuracy: 0.3937 - val_loss: 1.8761 - val_accuracy: 0.6212\n",
            "Epoch 4/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 1.8391 - accuracy: 0.4630 - val_loss: 1.6567 - val_accuracy: 0.6785\n",
            "Epoch 5/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 1.6487 - accuracy: 0.5238 - val_loss: 1.4368 - val_accuracy: 0.7253\n",
            "Epoch 6/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 1.4720 - accuracy: 0.5738 - val_loss: 1.2444 - val_accuracy: 0.7589\n",
            "Epoch 7/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 1.3161 - accuracy: 0.6177 - val_loss: 1.0794 - val_accuracy: 0.7856\n",
            "Epoch 8/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 1.1802 - accuracy: 0.6583 - val_loss: 0.9427 - val_accuracy: 0.8067\n",
            "Epoch 9/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 1.0662 - accuracy: 0.6899 - val_loss: 0.8315 - val_accuracy: 0.8216\n",
            "Epoch 10/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.9694 - accuracy: 0.7173 - val_loss: 0.7389 - val_accuracy: 0.8344\n",
            "Epoch 11/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.8832 - accuracy: 0.7417 - val_loss: 0.6658 - val_accuracy: 0.8456\n",
            "Epoch 12/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.8145 - accuracy: 0.7603 - val_loss: 0.6038 - val_accuracy: 0.8541\n",
            "Epoch 13/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.7582 - accuracy: 0.7785 - val_loss: 0.5538 - val_accuracy: 0.8650\n",
            "Epoch 14/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.7062 - accuracy: 0.7919 - val_loss: 0.5108 - val_accuracy: 0.8740\n",
            "Epoch 15/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.6604 - accuracy: 0.8067 - val_loss: 0.4744 - val_accuracy: 0.8817\n",
            "Epoch 16/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.6226 - accuracy: 0.8160 - val_loss: 0.4444 - val_accuracy: 0.8887\n",
            "Epoch 17/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.5909 - accuracy: 0.8262 - val_loss: 0.4173 - val_accuracy: 0.8948\n",
            "Epoch 18/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.5586 - accuracy: 0.8350 - val_loss: 0.3934 - val_accuracy: 0.9005\n",
            "Epoch 19/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.5338 - accuracy: 0.8427 - val_loss: 0.3723 - val_accuracy: 0.9044\n",
            "Epoch 20/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.5070 - accuracy: 0.8523 - val_loss: 0.3542 - val_accuracy: 0.9078\n",
            "Epoch 21/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.4869 - accuracy: 0.8581 - val_loss: 0.3381 - val_accuracy: 0.9105\n",
            "Epoch 22/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.4690 - accuracy: 0.8626 - val_loss: 0.3228 - val_accuracy: 0.9141\n",
            "Epoch 23/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.4511 - accuracy: 0.8684 - val_loss: 0.3091 - val_accuracy: 0.9171\n",
            "Epoch 24/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.4339 - accuracy: 0.8721 - val_loss: 0.2968 - val_accuracy: 0.9205\n",
            "Epoch 25/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.4186 - accuracy: 0.8763 - val_loss: 0.2857 - val_accuracy: 0.9225\n",
            "Epoch 26/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.4054 - accuracy: 0.8805 - val_loss: 0.2750 - val_accuracy: 0.9258\n",
            "Epoch 27/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3895 - accuracy: 0.8858 - val_loss: 0.2657 - val_accuracy: 0.9277\n",
            "Epoch 28/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3794 - accuracy: 0.8877 - val_loss: 0.2571 - val_accuracy: 0.9299\n",
            "Epoch 29/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3673 - accuracy: 0.8917 - val_loss: 0.2492 - val_accuracy: 0.9311\n",
            "Epoch 30/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3571 - accuracy: 0.8953 - val_loss: 0.2416 - val_accuracy: 0.9334\n",
            "Epoch 31/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3491 - accuracy: 0.8974 - val_loss: 0.2347 - val_accuracy: 0.9353\n",
            "Epoch 32/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3385 - accuracy: 0.9001 - val_loss: 0.2282 - val_accuracy: 0.9367\n",
            "Epoch 33/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3315 - accuracy: 0.9018 - val_loss: 0.2220 - val_accuracy: 0.9378\n",
            "Epoch 34/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3223 - accuracy: 0.9045 - val_loss: 0.2167 - val_accuracy: 0.9388\n",
            "Epoch 35/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.3184 - accuracy: 0.9058 - val_loss: 0.2112 - val_accuracy: 0.9403\n",
            "Epoch 36/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3082 - accuracy: 0.9085 - val_loss: 0.2061 - val_accuracy: 0.9416\n",
            "Epoch 37/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.3017 - accuracy: 0.9110 - val_loss: 0.2013 - val_accuracy: 0.9432\n",
            "Epoch 38/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2956 - accuracy: 0.9124 - val_loss: 0.1970 - val_accuracy: 0.9443\n",
            "Epoch 39/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.2902 - accuracy: 0.9149 - val_loss: 0.1930 - val_accuracy: 0.9456\n",
            "Epoch 40/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2862 - accuracy: 0.9153 - val_loss: 0.1887 - val_accuracy: 0.9467\n",
            "Epoch 41/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2792 - accuracy: 0.9171 - val_loss: 0.1853 - val_accuracy: 0.9474\n",
            "Epoch 42/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2735 - accuracy: 0.9188 - val_loss: 0.1815 - val_accuracy: 0.9484\n",
            "Epoch 43/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2682 - accuracy: 0.9205 - val_loss: 0.1784 - val_accuracy: 0.9491\n",
            "Epoch 44/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2657 - accuracy: 0.9221 - val_loss: 0.1752 - val_accuracy: 0.9498\n",
            "Epoch 45/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2609 - accuracy: 0.9218 - val_loss: 0.1720 - val_accuracy: 0.9503\n",
            "Epoch 46/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2554 - accuracy: 0.9242 - val_loss: 0.1689 - val_accuracy: 0.9514\n",
            "Epoch 47/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2501 - accuracy: 0.9254 - val_loss: 0.1660 - val_accuracy: 0.9516\n",
            "Epoch 48/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2485 - accuracy: 0.9259 - val_loss: 0.1635 - val_accuracy: 0.9523\n",
            "Epoch 49/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2449 - accuracy: 0.9277 - val_loss: 0.1612 - val_accuracy: 0.9527\n",
            "Epoch 50/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2408 - accuracy: 0.9287 - val_loss: 0.1585 - val_accuracy: 0.9535\n",
            "Epoch 51/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2364 - accuracy: 0.9294 - val_loss: 0.1561 - val_accuracy: 0.9537\n",
            "Epoch 52/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2334 - accuracy: 0.9302 - val_loss: 0.1539 - val_accuracy: 0.9545\n",
            "Epoch 53/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2304 - accuracy: 0.9316 - val_loss: 0.1520 - val_accuracy: 0.9547\n",
            "Epoch 54/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2293 - accuracy: 0.9319 - val_loss: 0.1496 - val_accuracy: 0.9555\n",
            "Epoch 55/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2248 - accuracy: 0.9332 - val_loss: 0.1476 - val_accuracy: 0.9559\n",
            "Epoch 56/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2233 - accuracy: 0.9325 - val_loss: 0.1459 - val_accuracy: 0.9565\n",
            "Epoch 57/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2194 - accuracy: 0.9350 - val_loss: 0.1439 - val_accuracy: 0.9566\n",
            "Epoch 58/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.2150 - accuracy: 0.9361 - val_loss: 0.1420 - val_accuracy: 0.9569\n",
            "Epoch 59/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2140 - accuracy: 0.9363 - val_loss: 0.1406 - val_accuracy: 0.9573\n",
            "Epoch 60/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2130 - accuracy: 0.9354 - val_loss: 0.1389 - val_accuracy: 0.9579\n",
            "Epoch 61/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2094 - accuracy: 0.9377 - val_loss: 0.1373 - val_accuracy: 0.9582\n",
            "Epoch 62/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2074 - accuracy: 0.9384 - val_loss: 0.1363 - val_accuracy: 0.9583\n",
            "Epoch 63/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2063 - accuracy: 0.9379 - val_loss: 0.1344 - val_accuracy: 0.9589\n",
            "Epoch 64/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.2022 - accuracy: 0.9391 - val_loss: 0.1328 - val_accuracy: 0.9591\n",
            "Epoch 65/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2014 - accuracy: 0.9396 - val_loss: 0.1314 - val_accuracy: 0.9595\n",
            "Epoch 66/1000\n",
            "3738/3738 [==============================] - 15s 4ms/step - loss: 0.1994 - accuracy: 0.9402 - val_loss: 0.1300 - val_accuracy: 0.9597\n",
            "Epoch 67/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1982 - accuracy: 0.9410 - val_loss: 0.1288 - val_accuracy: 0.9601\n",
            "Epoch 68/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1946 - accuracy: 0.9418 - val_loss: 0.1273 - val_accuracy: 0.9604\n",
            "Epoch 69/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1938 - accuracy: 0.9419 - val_loss: 0.1261 - val_accuracy: 0.9605\n",
            "Epoch 70/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1921 - accuracy: 0.9425 - val_loss: 0.1249 - val_accuracy: 0.9610\n",
            "Epoch 71/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1900 - accuracy: 0.9426 - val_loss: 0.1235 - val_accuracy: 0.9612\n",
            "Epoch 72/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1871 - accuracy: 0.9442 - val_loss: 0.1226 - val_accuracy: 0.9613\n",
            "Epoch 73/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1866 - accuracy: 0.9434 - val_loss: 0.1214 - val_accuracy: 0.9620\n",
            "Epoch 74/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1845 - accuracy: 0.9450 - val_loss: 0.1204 - val_accuracy: 0.9624\n",
            "Epoch 75/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1833 - accuracy: 0.9446 - val_loss: 0.1192 - val_accuracy: 0.9627\n",
            "Epoch 76/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1817 - accuracy: 0.9454 - val_loss: 0.1183 - val_accuracy: 0.9630\n",
            "Epoch 77/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1794 - accuracy: 0.9463 - val_loss: 0.1174 - val_accuracy: 0.9634\n",
            "Epoch 78/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1784 - accuracy: 0.9465 - val_loss: 0.1161 - val_accuracy: 0.9636\n",
            "Epoch 79/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1774 - accuracy: 0.9466 - val_loss: 0.1155 - val_accuracy: 0.9637\n",
            "Epoch 80/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1770 - accuracy: 0.9463 - val_loss: 0.1146 - val_accuracy: 0.9639\n",
            "Epoch 81/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1759 - accuracy: 0.9472 - val_loss: 0.1137 - val_accuracy: 0.9643\n",
            "Epoch 82/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1738 - accuracy: 0.9475 - val_loss: 0.1125 - val_accuracy: 0.9649\n",
            "Epoch 83/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1718 - accuracy: 0.9487 - val_loss: 0.1118 - val_accuracy: 0.9647\n",
            "Epoch 84/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1711 - accuracy: 0.9487 - val_loss: 0.1107 - val_accuracy: 0.9655\n",
            "Epoch 85/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1686 - accuracy: 0.9496 - val_loss: 0.1100 - val_accuracy: 0.9652\n",
            "Epoch 86/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1681 - accuracy: 0.9495 - val_loss: 0.1092 - val_accuracy: 0.9657\n",
            "Epoch 87/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1673 - accuracy: 0.9503 - val_loss: 0.1085 - val_accuracy: 0.9656\n",
            "Epoch 88/1000\n",
            "3738/3738 [==============================] - 15s 4ms/step - loss: 0.1652 - accuracy: 0.9501 - val_loss: 0.1078 - val_accuracy: 0.9659\n",
            "Epoch 89/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1641 - accuracy: 0.9502 - val_loss: 0.1069 - val_accuracy: 0.9662\n",
            "Epoch 90/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1639 - accuracy: 0.9502 - val_loss: 0.1062 - val_accuracy: 0.9666\n",
            "Epoch 91/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1607 - accuracy: 0.9514 - val_loss: 0.1054 - val_accuracy: 0.9665\n",
            "Epoch 92/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1604 - accuracy: 0.9513 - val_loss: 0.1048 - val_accuracy: 0.9670\n",
            "Epoch 93/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1601 - accuracy: 0.9513 - val_loss: 0.1040 - val_accuracy: 0.9673\n",
            "Epoch 94/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1597 - accuracy: 0.9518 - val_loss: 0.1034 - val_accuracy: 0.9674\n",
            "Epoch 95/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1581 - accuracy: 0.9528 - val_loss: 0.1027 - val_accuracy: 0.9676\n",
            "Epoch 96/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1553 - accuracy: 0.9529 - val_loss: 0.1020 - val_accuracy: 0.9679\n",
            "Epoch 97/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1576 - accuracy: 0.9519 - val_loss: 0.1013 - val_accuracy: 0.9679\n",
            "Epoch 98/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1569 - accuracy: 0.9521 - val_loss: 0.1008 - val_accuracy: 0.9683\n",
            "Epoch 99/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1538 - accuracy: 0.9534 - val_loss: 0.1000 - val_accuracy: 0.9683\n",
            "Epoch 100/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1553 - accuracy: 0.9531 - val_loss: 0.0994 - val_accuracy: 0.9685\n",
            "Epoch 101/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1532 - accuracy: 0.9539 - val_loss: 0.0990 - val_accuracy: 0.9688\n",
            "Epoch 102/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1529 - accuracy: 0.9539 - val_loss: 0.0983 - val_accuracy: 0.9690\n",
            "Epoch 103/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1502 - accuracy: 0.9546 - val_loss: 0.0977 - val_accuracy: 0.9690\n",
            "Epoch 104/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1506 - accuracy: 0.9543 - val_loss: 0.0973 - val_accuracy: 0.9692\n",
            "Epoch 105/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1479 - accuracy: 0.9553 - val_loss: 0.0965 - val_accuracy: 0.9692\n",
            "Epoch 106/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1491 - accuracy: 0.9547 - val_loss: 0.0960 - val_accuracy: 0.9700\n",
            "Epoch 107/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1467 - accuracy: 0.9555 - val_loss: 0.0956 - val_accuracy: 0.9699\n",
            "Epoch 108/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1464 - accuracy: 0.9554 - val_loss: 0.0950 - val_accuracy: 0.9701\n",
            "Epoch 109/1000\n",
            "3738/3738 [==============================] - 17s 5ms/step - loss: 0.1466 - accuracy: 0.9559 - val_loss: 0.0945 - val_accuracy: 0.9705\n",
            "Epoch 110/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1452 - accuracy: 0.9561 - val_loss: 0.0943 - val_accuracy: 0.9704\n",
            "Epoch 111/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1456 - accuracy: 0.9561 - val_loss: 0.0938 - val_accuracy: 0.9705\n",
            "Epoch 112/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1438 - accuracy: 0.9569 - val_loss: 0.0931 - val_accuracy: 0.9709\n",
            "Epoch 113/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1416 - accuracy: 0.9569 - val_loss: 0.0927 - val_accuracy: 0.9708\n",
            "Epoch 114/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1436 - accuracy: 0.9558 - val_loss: 0.0922 - val_accuracy: 0.9711\n",
            "Epoch 115/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1413 - accuracy: 0.9573 - val_loss: 0.0916 - val_accuracy: 0.9712\n",
            "Epoch 116/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1427 - accuracy: 0.9570 - val_loss: 0.0914 - val_accuracy: 0.9711\n",
            "Epoch 117/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1391 - accuracy: 0.9571 - val_loss: 0.0908 - val_accuracy: 0.9712\n",
            "Epoch 118/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1381 - accuracy: 0.9576 - val_loss: 0.0903 - val_accuracy: 0.9716\n",
            "Epoch 119/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1380 - accuracy: 0.9578 - val_loss: 0.0901 - val_accuracy: 0.9716\n",
            "Epoch 120/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1380 - accuracy: 0.9581 - val_loss: 0.0893 - val_accuracy: 0.9719\n",
            "Epoch 121/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1378 - accuracy: 0.9584 - val_loss: 0.0891 - val_accuracy: 0.9719\n",
            "Epoch 122/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1385 - accuracy: 0.9579 - val_loss: 0.0886 - val_accuracy: 0.9721\n",
            "Epoch 123/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1354 - accuracy: 0.9595 - val_loss: 0.0881 - val_accuracy: 0.9722\n",
            "Epoch 124/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1358 - accuracy: 0.9589 - val_loss: 0.0878 - val_accuracy: 0.9725\n",
            "Epoch 125/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1354 - accuracy: 0.9595 - val_loss: 0.0875 - val_accuracy: 0.9722\n",
            "Epoch 126/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1355 - accuracy: 0.9593 - val_loss: 0.0873 - val_accuracy: 0.9726\n",
            "Epoch 127/1000\n",
            "3738/3738 [==============================] - 15s 4ms/step - loss: 0.1342 - accuracy: 0.9592 - val_loss: 0.0867 - val_accuracy: 0.9729\n",
            "Epoch 128/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1333 - accuracy: 0.9593 - val_loss: 0.0865 - val_accuracy: 0.9728\n",
            "Epoch 129/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1338 - accuracy: 0.9593 - val_loss: 0.0858 - val_accuracy: 0.9731\n",
            "Epoch 130/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1346 - accuracy: 0.9593 - val_loss: 0.0855 - val_accuracy: 0.9735\n",
            "Epoch 131/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1307 - accuracy: 0.9604 - val_loss: 0.0852 - val_accuracy: 0.9737\n",
            "Epoch 132/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1305 - accuracy: 0.9602 - val_loss: 0.0851 - val_accuracy: 0.9733\n",
            "Epoch 133/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1297 - accuracy: 0.9606 - val_loss: 0.0845 - val_accuracy: 0.9738\n",
            "Epoch 134/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1293 - accuracy: 0.9606 - val_loss: 0.0845 - val_accuracy: 0.9738\n",
            "Epoch 135/1000\n",
            "3738/3738 [==============================] - 15s 4ms/step - loss: 0.1306 - accuracy: 0.9599 - val_loss: 0.0840 - val_accuracy: 0.9742\n",
            "Epoch 136/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1290 - accuracy: 0.9603 - val_loss: 0.0835 - val_accuracy: 0.9745\n",
            "Epoch 137/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1279 - accuracy: 0.9611 - val_loss: 0.0833 - val_accuracy: 0.9745\n",
            "Epoch 138/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1287 - accuracy: 0.9611 - val_loss: 0.0831 - val_accuracy: 0.9746\n",
            "Epoch 139/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1266 - accuracy: 0.9614 - val_loss: 0.0825 - val_accuracy: 0.9746\n",
            "Epoch 140/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1276 - accuracy: 0.9612 - val_loss: 0.0823 - val_accuracy: 0.9746\n",
            "Epoch 141/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1271 - accuracy: 0.9613 - val_loss: 0.0819 - val_accuracy: 0.9750\n",
            "Epoch 142/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1269 - accuracy: 0.9620 - val_loss: 0.0817 - val_accuracy: 0.9753\n",
            "Epoch 143/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1266 - accuracy: 0.9613 - val_loss: 0.0812 - val_accuracy: 0.9754\n",
            "Epoch 144/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1251 - accuracy: 0.9620 - val_loss: 0.0808 - val_accuracy: 0.9752\n",
            "Epoch 145/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1243 - accuracy: 0.9623 - val_loss: 0.0808 - val_accuracy: 0.9755\n",
            "Epoch 146/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1240 - accuracy: 0.9620 - val_loss: 0.0802 - val_accuracy: 0.9757\n",
            "Epoch 147/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1241 - accuracy: 0.9624 - val_loss: 0.0800 - val_accuracy: 0.9757\n",
            "Epoch 148/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1241 - accuracy: 0.9631 - val_loss: 0.0797 - val_accuracy: 0.9755\n",
            "Epoch 149/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1237 - accuracy: 0.9626 - val_loss: 0.0793 - val_accuracy: 0.9760\n",
            "Epoch 150/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1225 - accuracy: 0.9634 - val_loss: 0.0792 - val_accuracy: 0.9762\n",
            "Epoch 151/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1228 - accuracy: 0.9628 - val_loss: 0.0789 - val_accuracy: 0.9765\n",
            "Epoch 152/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1217 - accuracy: 0.9625 - val_loss: 0.0788 - val_accuracy: 0.9764\n",
            "Epoch 153/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1211 - accuracy: 0.9632 - val_loss: 0.0785 - val_accuracy: 0.9765\n",
            "Epoch 154/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1212 - accuracy: 0.9631 - val_loss: 0.0782 - val_accuracy: 0.9766\n",
            "Epoch 155/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1203 - accuracy: 0.9631 - val_loss: 0.0779 - val_accuracy: 0.9768\n",
            "Epoch 156/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1205 - accuracy: 0.9639 - val_loss: 0.0774 - val_accuracy: 0.9768\n",
            "Epoch 157/1000\n",
            "3738/3738 [==============================] - 15s 4ms/step - loss: 0.1200 - accuracy: 0.9637 - val_loss: 0.0772 - val_accuracy: 0.9768\n",
            "Epoch 158/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1195 - accuracy: 0.9638 - val_loss: 0.0769 - val_accuracy: 0.9772\n",
            "Epoch 159/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1175 - accuracy: 0.9642 - val_loss: 0.0768 - val_accuracy: 0.9769\n",
            "Epoch 160/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1174 - accuracy: 0.9645 - val_loss: 0.0766 - val_accuracy: 0.9771\n",
            "Epoch 161/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1184 - accuracy: 0.9637 - val_loss: 0.0763 - val_accuracy: 0.9771\n",
            "Epoch 162/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1169 - accuracy: 0.9648 - val_loss: 0.0762 - val_accuracy: 0.9773\n",
            "Epoch 163/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1187 - accuracy: 0.9638 - val_loss: 0.0759 - val_accuracy: 0.9772\n",
            "Epoch 164/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1164 - accuracy: 0.9646 - val_loss: 0.0755 - val_accuracy: 0.9773\n",
            "Epoch 165/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1166 - accuracy: 0.9642 - val_loss: 0.0754 - val_accuracy: 0.9774\n",
            "Epoch 166/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1163 - accuracy: 0.9647 - val_loss: 0.0751 - val_accuracy: 0.9778\n",
            "Epoch 167/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1164 - accuracy: 0.9645 - val_loss: 0.0748 - val_accuracy: 0.9777\n",
            "Epoch 168/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1140 - accuracy: 0.9651 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
            "Epoch 169/1000\n",
            "3738/3738 [==============================] - 17s 5ms/step - loss: 0.1150 - accuracy: 0.9650 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
            "Epoch 170/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1150 - accuracy: 0.9647 - val_loss: 0.0741 - val_accuracy: 0.9780\n",
            "Epoch 171/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1141 - accuracy: 0.9654 - val_loss: 0.0738 - val_accuracy: 0.9780\n",
            "Epoch 172/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1150 - accuracy: 0.9651 - val_loss: 0.0735 - val_accuracy: 0.9780\n",
            "Epoch 173/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1154 - accuracy: 0.9653 - val_loss: 0.0736 - val_accuracy: 0.9783\n",
            "Epoch 174/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1135 - accuracy: 0.9655 - val_loss: 0.0732 - val_accuracy: 0.9781\n",
            "Epoch 175/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1133 - accuracy: 0.9661 - val_loss: 0.0731 - val_accuracy: 0.9782\n",
            "Epoch 176/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1134 - accuracy: 0.9657 - val_loss: 0.0728 - val_accuracy: 0.9781\n",
            "Epoch 177/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1126 - accuracy: 0.9656 - val_loss: 0.0726 - val_accuracy: 0.9783\n",
            "Epoch 178/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1131 - accuracy: 0.9655 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
            "Epoch 179/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1113 - accuracy: 0.9662 - val_loss: 0.0722 - val_accuracy: 0.9785\n",
            "Epoch 180/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1131 - accuracy: 0.9659 - val_loss: 0.0719 - val_accuracy: 0.9786\n",
            "Epoch 181/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1115 - accuracy: 0.9658 - val_loss: 0.0717 - val_accuracy: 0.9785\n",
            "Epoch 182/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1105 - accuracy: 0.9663 - val_loss: 0.0716 - val_accuracy: 0.9787\n",
            "Epoch 183/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1121 - accuracy: 0.9654 - val_loss: 0.0713 - val_accuracy: 0.9787\n",
            "Epoch 184/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1104 - accuracy: 0.9662 - val_loss: 0.0711 - val_accuracy: 0.9789\n",
            "Epoch 185/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1087 - accuracy: 0.9672 - val_loss: 0.0710 - val_accuracy: 0.9789\n",
            "Epoch 186/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1110 - accuracy: 0.9660 - val_loss: 0.0710 - val_accuracy: 0.9788\n",
            "Epoch 187/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1095 - accuracy: 0.9662 - val_loss: 0.0704 - val_accuracy: 0.9791\n",
            "Epoch 188/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1087 - accuracy: 0.9675 - val_loss: 0.0705 - val_accuracy: 0.9792\n",
            "Epoch 189/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1092 - accuracy: 0.9672 - val_loss: 0.0702 - val_accuracy: 0.9792\n",
            "Epoch 190/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1092 - accuracy: 0.9673 - val_loss: 0.0700 - val_accuracy: 0.9793\n",
            "Epoch 191/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1091 - accuracy: 0.9670 - val_loss: 0.0699 - val_accuracy: 0.9794\n",
            "Epoch 192/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1091 - accuracy: 0.9669 - val_loss: 0.0697 - val_accuracy: 0.9793\n",
            "Epoch 193/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1085 - accuracy: 0.9674 - val_loss: 0.0694 - val_accuracy: 0.9794\n",
            "Epoch 194/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1064 - accuracy: 0.9678 - val_loss: 0.0693 - val_accuracy: 0.9795\n",
            "Epoch 195/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1071 - accuracy: 0.9673 - val_loss: 0.0692 - val_accuracy: 0.9794\n",
            "Epoch 196/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1065 - accuracy: 0.9675 - val_loss: 0.0689 - val_accuracy: 0.9794\n",
            "Epoch 197/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1065 - accuracy: 0.9679 - val_loss: 0.0688 - val_accuracy: 0.9797\n",
            "Epoch 198/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1055 - accuracy: 0.9682 - val_loss: 0.0688 - val_accuracy: 0.9798\n",
            "Epoch 199/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1074 - accuracy: 0.9675 - val_loss: 0.0686 - val_accuracy: 0.9797\n",
            "Epoch 200/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1069 - accuracy: 0.9676 - val_loss: 0.0684 - val_accuracy: 0.9797\n",
            "Epoch 201/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1057 - accuracy: 0.9680 - val_loss: 0.0681 - val_accuracy: 0.9800\n",
            "Epoch 202/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1059 - accuracy: 0.9676 - val_loss: 0.0680 - val_accuracy: 0.9801\n",
            "Epoch 203/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1052 - accuracy: 0.9679 - val_loss: 0.0678 - val_accuracy: 0.9801\n",
            "Epoch 204/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1046 - accuracy: 0.9686 - val_loss: 0.0677 - val_accuracy: 0.9802\n",
            "Epoch 205/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1043 - accuracy: 0.9687 - val_loss: 0.0674 - val_accuracy: 0.9801\n",
            "Epoch 206/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1038 - accuracy: 0.9688 - val_loss: 0.0673 - val_accuracy: 0.9801\n",
            "Epoch 207/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1036 - accuracy: 0.9684 - val_loss: 0.0670 - val_accuracy: 0.9801\n",
            "Epoch 208/1000\n",
            "3738/3738 [==============================] - 15s 4ms/step - loss: 0.1051 - accuracy: 0.9680 - val_loss: 0.0668 - val_accuracy: 0.9803\n",
            "Epoch 209/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1033 - accuracy: 0.9684 - val_loss: 0.0666 - val_accuracy: 0.9804\n",
            "Epoch 210/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1043 - accuracy: 0.9682 - val_loss: 0.0666 - val_accuracy: 0.9806\n",
            "Epoch 211/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1025 - accuracy: 0.9688 - val_loss: 0.0665 - val_accuracy: 0.9806\n",
            "Epoch 212/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1039 - accuracy: 0.9689 - val_loss: 0.0664 - val_accuracy: 0.9802\n",
            "Epoch 213/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1021 - accuracy: 0.9687 - val_loss: 0.0662 - val_accuracy: 0.9808\n",
            "Epoch 214/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1029 - accuracy: 0.9683 - val_loss: 0.0660 - val_accuracy: 0.9807\n",
            "Epoch 215/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1017 - accuracy: 0.9693 - val_loss: 0.0660 - val_accuracy: 0.9810\n",
            "Epoch 216/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1016 - accuracy: 0.9689 - val_loss: 0.0657 - val_accuracy: 0.9810\n",
            "Epoch 217/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1021 - accuracy: 0.9690 - val_loss: 0.0654 - val_accuracy: 0.9807\n",
            "Epoch 218/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1010 - accuracy: 0.9696 - val_loss: 0.0654 - val_accuracy: 0.9808\n",
            "Epoch 219/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1015 - accuracy: 0.9692 - val_loss: 0.0654 - val_accuracy: 0.9807\n",
            "Epoch 220/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1013 - accuracy: 0.9697 - val_loss: 0.0652 - val_accuracy: 0.9809\n",
            "Epoch 221/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1022 - accuracy: 0.9695 - val_loss: 0.0651 - val_accuracy: 0.9810\n",
            "Epoch 222/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1008 - accuracy: 0.9692 - val_loss: 0.0649 - val_accuracy: 0.9812\n",
            "Epoch 223/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1008 - accuracy: 0.9689 - val_loss: 0.0647 - val_accuracy: 0.9811\n",
            "Epoch 224/1000\n",
            "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1004 - accuracy: 0.9693 - val_loss: 0.0645 - val_accuracy: 0.9811\n",
            "Epoch 225/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1002 - accuracy: 0.9695 - val_loss: 0.0645 - val_accuracy: 0.9812\n",
            "Epoch 226/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1017 - accuracy: 0.9690 - val_loss: 0.0644 - val_accuracy: 0.9813\n",
            "Epoch 227/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1007 - accuracy: 0.9698 - val_loss: 0.0643 - val_accuracy: 0.9814\n",
            "Epoch 228/1000\n",
            "3738/3738 [==============================] - 17s 5ms/step - loss: 0.0999 - accuracy: 0.9701 - val_loss: 0.0641 - val_accuracy: 0.9814\n",
            "Epoch 229/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0983 - accuracy: 0.9701 - val_loss: 0.0639 - val_accuracy: 0.9812\n",
            "Epoch 230/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0989 - accuracy: 0.9697 - val_loss: 0.0640 - val_accuracy: 0.9815\n",
            "Epoch 231/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1001 - accuracy: 0.9695 - val_loss: 0.0638 - val_accuracy: 0.9814\n",
            "Epoch 232/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0987 - accuracy: 0.9702 - val_loss: 0.0636 - val_accuracy: 0.9816\n",
            "Epoch 233/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0990 - accuracy: 0.9701 - val_loss: 0.0634 - val_accuracy: 0.9816\n",
            "Epoch 234/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0977 - accuracy: 0.9700 - val_loss: 0.0631 - val_accuracy: 0.9816\n",
            "Epoch 235/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0985 - accuracy: 0.9697 - val_loss: 0.0631 - val_accuracy: 0.9814\n",
            "Epoch 236/1000\n",
            "3738/3738 [==============================] - 15s 4ms/step - loss: 0.0991 - accuracy: 0.9697 - val_loss: 0.0630 - val_accuracy: 0.9815\n",
            "Epoch 237/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0971 - accuracy: 0.9704 - val_loss: 0.0627 - val_accuracy: 0.9815\n",
            "Epoch 238/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0979 - accuracy: 0.9700 - val_loss: 0.0629 - val_accuracy: 0.9818\n",
            "Epoch 239/1000\n",
            "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0971 - accuracy: 0.9701 - val_loss: 0.0628 - val_accuracy: 0.9818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f70df318630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nya0oZgdDOhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=load_model('/content/drive/My Drive/Data_soduku/Digit_Model_34.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rvfFpldgWTMk",
        "colab": {}
      },
      "source": [
        "metrics = pd.DataFrame(model.history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LNdrg_4gU25u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a693d0cb-4620-4487-f37b-a4dcf13d67c8"
      },
      "source": [
        "metrics[['loss','val_loss']].plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f70dfd25940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0CntQtJ0U8dO",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Data_soduku/Digit_Model_P21.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eUqrSX49xNkn",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ahVXrsUU_B5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "6d4220d0-4b70-4d0f-a73e-ff75746e45ce"
      },
      "source": [
        "test_images = X_test[170:174]\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28)\n",
        "print (\"Test images shape: {}\".format(test_images.shape))\n",
        "for i, test_image in enumerate(test_images, start=1):\n",
        "    org_image = test_image\n",
        "    test_image = test_image.reshape(1,28,28,1)\n",
        "    prediction = model.predict_classes(test_image, verbose=0)\n",
        "    print (\"Predicted digit: {}\".format(prediction[0]))\n",
        "    plt.subplot(220+i)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Predicted digit: {}\".format(prediction[0]))\n",
        "    plt.imshow(org_image, cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test images shape: (4, 28, 28)\n",
            "Predicted digit: 7\n",
            "Predicted digit: 4\n",
            "Predicted digit: 7\n",
            "Predicted digit: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAD3CAYAAABFL3JUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZgUlEQVR4nO3dfdBVReEH8O+Xl+cBHhiBgCx6EBNDjEkxCylQi2a0EUdByqxAbLDpZWyGPxoVrWCC0WZM+9mTWc5YEomWUVppJtNoOkAMhJpYBA4iIDy8x4u8PbC/P+55DnvWe/aee59zn/vsfb6fmTvseXbPOXvP2bvs7t27h8YYiIh0dT1qnQERkSxUWYlIEFRZiUgQVFmJSBBUWYlIEFRZiUgQalpZkfwlyQVReBLJ9Z10XkNyVMa080gujsIjSB4i2TPDfpnTSv1R2c5fycqK5Jskj0SZa41uQv+8M2KMedEYMzpDfmaRfCnv82dhjHnLGNPfGHOy3LQknyc5O+u5ogJ+yHkZktd15D3IaSrbp3Vm2baRnBmV65L7Z21ZXW2M6Q/gIgAXA7izyEl7lZdN8YkKeP/2F4ApAA4B+EuNs1ZvVLZrhOQgAHMBrMuSvqxuoDFmG4BnAIyNTmZIfpPkBgAbor9NIfkyyf0kl5P8iJW5cST/SfIgyccB9LHiLie51dpuJrmU5C6Se0i2kBwD4EEAE6L/DfdHaRtJ3kPyreh/yAdJ9rWO9W2S20m+TfIrvvdI8mySL0R5fA7AECtuZPSee1lp/x6lXUbyJ1azOk5LciGASQBaony3lHPdIzcCeMIYc7iCfaUEle2alO27ANwPYHem1MYY7wvAmwA+E4WbUagFvx9tGwDPARgMoC+AcQB2AhgPoCcKH7A3ATQCaACwGcAcAL0BTAdwAsCC6FiXA9gahXsCeAXAfQCaULjxE6O4WQBecvJ4H4CnonwMAPBHAHdFcVcCaEWhEDYBeDTK96iU97sCwL1Rni8FcBDA4ihuZLRvLyvtPdF7mwjggCft8wBmO+f6E4DbMtyDpigfl5dKq1f2l8p27co2gI8DWI1Cg+ld+xfdJ+MNPQRgf3RDHgDQ17qhn7bS/rT9Zlt/Ww/gsujivA2AVtzylBs6AcCu9ovhHC9xQwEQwGEA51h/mwBgUxR+GMDdVtyH0m4ogBEA2gA0WX97tNhNstL2s9IuLueGlvGhmgFgk33t9Or4S2W7NmUbhQp7NYBLytk/a1/8WmPMspS4LVb4LAA3krzF+lsDgPdHb26biXIX2ZxyzGYAm40xbRnyNhRAPwBrSLb/jShcEETnXpPhnO1p95lkV2tzlJ9iafcaY96x/rYlJW1H3QhgkXPtJB8q28XTVrNsfwPAq8aYleXslMfUBfsGbQGw0Bgz0Hr1M8YsAbAdwHBaVx2FGryYLQBGpAxsuh/Y3QCOAPiwdc4zTGHQFNF57Yucds72tININmVIvx3AYJL9rL/5bmZFFQ3JZhT+Z15Uyf7SISrbp+VZticDmEpyB8kdAD4B4Ielxrvynmf1EICvkRzPgiaSV5EcgEIfuA3At0j2JjkNhX5rMatQuGB3R8foQ/KTUVwrgA+QbAAAY8yp6Lz3kRwGACSHk7wiSv8bALNInh9d/O+lZd4YsxmF5ul8kg0kJwK4ukTaeVHaCWlprXx/0BOfZgaA5caYNyrYV/Kjsp2u3LI9C8AYABdGr9UA5gO4w7dTrpWVMWY1gJsBtADYB2BjlDEYY44DmBZt7wVwPYClKcc5icLFGQXgLQBbo/QA8DcUBkJ3kGz/FuHW6FwrSR4AsAzA6OhYzwD4UbTfxuhfny+iMIi6F4Wb72vRfAmFMYQ9ABYAeBzAsZS0/wdgOsl9JO8HAJLPkJxbIj8zATxSIo1Umcp2fmXbGLPfGLOj/QXgOIADxpj/+TJPDYPkJ/rK+j/GmNT/4URC1BXKtn4b2AEkP0byHJI9SF4J4BoAf6h1vkQ6qiuWbc3M7ZgzUWjuvweF5vzXjTFra5slkVx0ubKtbqCIBEHdQBEJQtZuoJpfXQdLJ5EyqGx3Hd6yrZaViARBlZWIBEGVlYgEQZWViARBlZWIBEGVlYgEQTPYO+jEiRNxeNu2bYm4o0ePpu5nxzU1NSXizj333JxyJ1I/1LISkSCoshKRIKiyEpEgVDRmNWHChNS4rOM0Z599diLu6aefriQrNbdu3elHno0bN66iY1x44YWJ7bVrtXBDZ0muRJzk+5G/b7+u7OKLL05sf/WrX43DN998cyKu2u+x3EUU1LISkSCoshKRIFTUDVy5sqwn6BTVp0+f0olEpGz1ukadWlYiEgRVViISBFVWIhKEmv3cxjfFoRbnt7+mdfv8vvG1PMbean0tJDyzZs2Kw7/4xS9yOWZXn46hlpWIBEGVlYgEoWbdwDfeeCOxbc9ozzoLPq84ABgwYEAcnjNnTiJu/vz5cfjUqVNlHTcLdQOllBtuuCGx3V26fja1rEQkCKqsRCQIqqxEJAhZHx+fSBRSPzerkSNHxuFNmzalptu5c2die+bMmXH42Wef7fC5S50feshprkimfgC60qoLef2Epit9dou8Jz3kVETCp8pKRILQbR8Y4TaHszaz29raEtuVdv1smrogxdRj168j1LISkSCoshKRIKiyEpEgdNsxq2HDhiW2169fn5r25MmTcXjDhg1Vy5N0b7UYo8rjnJ01JqaWlYgEQZWViASh23YD3dUTGhsbU9MePnw4Dl9//fW550VTF7qvzuiGVeMBErWYDqGWlYgEQZWViARBlZWIBKHbjFk1NTUltn/1q19l3vfIkSNxuLW1Nbc8iVTKN2akh5yKiNSQKisRCUK36Qbas9AB4IorrkhN666s0NLSUpU8tdPUhe6j0i5arVdOqPX5AbWsRCQQqqxEJAiqrEQkCHU9ZtWzZ884/PnPfz7zfidOnEhsL1iwILc8SfeTx1SCWk9HcM+vn9uIiKRQZSUiQeg2zw10u3a9eqX3gLdu3ZrYbm5urkqe0pS4J+Fd/C6sM54bWOsuXB6q8ZnXcwNFpC6pshKRIKiyEpEg1PXUhSFDhsRh9+c2vjGrqVOnJrbt/npnjD/YP7/p06dP1c8n+aqHMSqg641Nq2UlIkFQZSUiQVBlJSJBqOt5Vnv27InDgwcP9qa1n3bjrira2Uu42CuTFhmzCuPiB6Ia86xCGrOq5WdZ86xEpC6pshKRINT11IUePbLXxU8++WRF+1WDpi6ELa+uVTW6k1/4whdyP2ZnUctKRIKgykpEgqDKSkSCUFdTFx577LHE9rRp0+Jw7969vfsOHTo0Du/evTvfjJVp3759cXjgwIFudNe8+IHqjCVisuqMKQ9d6bOrqQsiUpdUWYlIEOpq6sKkSZMS276u38GDBxPb9sMlak0PPZU8daWuX0eoZSUiQVBlJSJBUGUlIkEIfsxq8uTJcbhv376Z95s9e3Zi254uINJZQlqhodbUshKRIKiyEpEgBN8N/PGPfxyHi8z2TrVq1arE9vHjx3PLU0dp6kL96m6z1POklpWIBEGVlYgEQZWViAQhuDEr92EO9ravr/7aa68lto8dO5ZvxnKkMSspx6c+9alaZ6FTqGUlIkFQZSUiQQiuG/jrX/86sf3e974303433XRTYru1tTW3PIn4VGO6Qr1OT/BRy0pEgqDKSkSCoMpKRIIQ3JjViBEjEtuNjY2pae2xgra2tkTcqVOn8s1YjjR1ob7Y40ud/RCKeqKWlYgEQZWViAQhuG7gZZddlti2H/Tg6z6payV5qsZ0BC3E56eWlYgEQZWViARBlZWIBCG4MSv34aSV6tOnT03jfGl79QrutohUnVpWIhIEVVYiEoSK+hsrVqxIjcujm9TZXTSRYjSjvHOVmrqhlpWIBEGVlYgEQZWViASBmuIvIiFQy0pEgqDKSkSCoMpKRIKgykpEglDTyorkL0kuiMKTSK7vpPMakqMypp1HcnEUHkHyEMmeGfbLnFbqj8p2/kpWViTfJHkkylxrdBP6550RY8yLxpjRGfIzi+RLeZ8/C2PMW8aY/saYk+WmJfk8ydlZzxUV8EPOy5C8riPvQU5T2T6tM8u2jeTMqFyX3D9ry+pqY0x/ABcBuBjAnUVOqqUCchQV8P7tLwBTABwC8JcaZ63eqGzXCMlBAOYCWJclfVndQGPMNgDPABgbncyQ/CbJDQA2RH+bQvJlkvtJLif5EStz40j+k+RBko8D6GPFXU5yq7XdTHIpyV0k95BsITkGwIMAJkT/G+6P0jaSvIfkW9H/kA+S7Gsd69skt5N8m+RXfO+R5NkkX4jy+ByAIVbcyOg997LS/j1Ku4zkT6xmdZyW5EIAkwC0RPluKee6R24E8IQx5nAF+0oJKts1Kdt3AbgfwO5MqY0x3heANwF8Jgo3o1ALfj/aNgCeAzAYQF8A4wDsBDAeQE8UPmBvAmgE0ABgM4A5AHoDmA7gBIAF0bEuB7A1CvcE8AqA+wA0oXDjJ0ZxswC85OTxPgBPRfkYAOCPAO6K4q4E0IpCIWwC8GiU71Ep73cFgHujPF8K4CCAxVHcyGjfXlbae6L3NhHAAU/a5wHMds71JwC3ZbgHTVE+Li+VVq/sL5Xt2pVtAB8HsBqFBtO79i+6T8YbegjA/uiGPACgr3VDP22l/Wn7zbb+th7AZdHFeRvRrPkobnnKDZ0AYFf7xXCOl7ihAAjgMIBzrL9NALApCj8M4G4r7kNpNxTACABtAJqsvz1a7CZZaftZaReXc0PL+FDNALDJvnZ6dfylsl2bso1Chb0awCXl7J+1L36tMWZZStwWK3wWgBtJ3mL9rQHA+6M3t81EuYtsTjlmM4DNxpi2lHjbUAD9AKzh6SU9iMIFQXTuNRnO2Z52n0l2tTZH+SmWdq8x5h3rb1tS0nbUjQAWOddO8qGyXTxtNcv2NwC8aoxZWc5OeUxdsG/QFgALjTEDrVc/Y8wSANsBDCcTiwQlH6+cPM6IlIFN9wO7G8ARAB+2znmGKQyaIjqvfZHTztmedhDJpgzptwMYTLKf9TffzayooiHZjML/zIsq2V86RGX7tDzL9mQAU0nuILkDwCcA/LDUeFfe86weAvA1kuNZ0ETyKpIDUOgDtwH4FsneJKeh0G8tZhUKF+zu6Bh9SH4yimsF8AGSDQBgjDkVnfc+ksMAgORwkldE6X8DYBbJ86OL/720zBtjNqPQPJ1PsoHkRABXl0g7L0o7IS2tle8PeuLTzACw3BjzRgX7Sn5UttOVW7ZnARgD4MLotRrAfAB3+HbKtbIyxqwGcDOAFgD7AGyMMgZjzHEA06LtvQCuB7A05TgnUbg4owC8BWBrlB4A/obCQOgOku3fItwanWslyQMAlgEYHR3rGQA/ivbbGP3r80UUBlH3onDzfS2aL6EwhrAHwAIAjwM4lpL2/wBMJ7mP5P0AQPIZknNL5GcmgEdKpJEqU9nOr2wbY/YbY3a0vwAcB3DAGPM/X+a1REyOoq+s/2OMSf0fTiREXaFs67eBHUDyYyTPIdmD5JUArgHwh1rnS6SjumLZ1szcjjkTheb+e1Bozn/dGLO2tlkSyUWXK9vqBopIENQNFJEgZO0GqvnVdehhdjlyJ9oy47MC3R6Jvd2jRz5tgFOnTqUe0z6fm2d7P3dfN9/2vidPJhdc6Nnz9AowvmP6lJkX78VXy0pEgqDKSkSCoMpKRIJQ0dQFu2s5efLkRNzy5cvj8PDhwxNxY8aMicMjRiR/lnTeeefF4bFjxybiBg4cGIeHDBmSiDvjjDPicENDQyKusbGx+BsIiNuN17e3+fINk7jjLXZadz972zee5dsvL+WMmdl5s8eogMrHzHx58R2zFLWsRCQIqqxEJAhZJ4Wmfr2rbkl1FekGaupCvlILsK9b5FNO187+/PTqlRyVsc/nO7evqwUAvXv3jsMnTpxIPY77ft2pDHkrUndo6oKIhE+VlYgEQZWViAQhuFUXjh8/nthubW2Nw6+//noi7uWXX47DW7duTcT997//TWzb8e5xfOxzXHDBBZn3k67JHqcpZ5zI97MVH/s4bW3py7K741l2Wt8YFZAcp3KPY48bufm28+b72Yx7Lezj5DmmrZaViARBlZWIBKFm3UC3OVrtr0mr5be//W0cVjcwfPbX975Z277Z7ZXync/9fPimD7ndSfu47nF8q0X4uoG+86Udo9RxSlHLSkSCoMpKRIKgykpEglCzn9tU49fmtVDtnxvp5zbV5a4Uaqt0xU/3Zyu+MlLpGI5vxU3f+SpdxcO3WoR7nXxjWCXOrZ/biEj4VFmJSBBqNnXhySefTGx/+ctfjsMHDhzo7Owk+LqoWmWivrj32v5qv5yv3e2un28ajq9sud1Heyb60aNHU/NSakE/u8y65ff222+Pw9OmTUvEzZgxIw6vX78+9fzudfFdCztvbnfRnc7kUstKRIKgykpEgqDKSkSC0G1XCt21a1die9iwYalpx48fH4dXrlxZtTwVo6kLVZdagH3jS75xoXJW3Mz6Wfrc5z6X2F6yZEkc3rhxYyLOfviKa+TIkYntFStWxOEzzzwzEbdgwYI4/J3vfCf1mJW+3yLjWZq6ICLhU2UlIkEIbvG9vJSzysOdd95ZxZxIV2KXC98idm6Xzde9qXRaw3XXXReHf/7zn6fut27dutQ4l/vczaFDh6am/f3vf5/pmOXMws/6vMFi1LISkSCoshKRIKiyEpEgdJsxK/fhju973/tS0950002J7SlTplQlT1J7vp+K+B4I2tDQkNi2fzrijmdl/QnP1KlTE3H2KrQuexz1rrvuSk3n8j34wY3z/aTHt/potahlJSJBUGUlIkHoNt1At9nu8/DDD1cxJ+U566yzap2FuuZ7SIPvq3X3+ZV22nJWPbjjjjvi8G233ZaIs7uhCxcuTMS52zbf4n/u58B+H77PiJtvXxexWr9qUctKRIKgykpEgqDKSkSC0G3GrEJ1ySWX1DoLdc33s5lyxl58afv37x+H586dm4i79dZb47A7fmZPT/jBD36Qenzfaqcud6zNHt9yj2PHuat42lM1OuvhL2pZiUgQVFmJSBDquhtYTvO0qy4iqG5gdfnKiG+2uTs9wOZ2wx555JE47P4awj6H29Wzpye4+bS7Ze6DF3z5drtz9vb27dsTcTt27EBXopaViARBlZWIBEGVlYgEoa7HrOqBxqw6lz12Wc7DO232T2iAd6+mYJs+fXoc/t3vfpeIs3/+4q4AYY9TlXoYq51vtzzZx922bVsizt6u9OEZeVLLSkSCoMpKRIJQV93AGTNmZE7bVacquNQNrB3fzHB3hYKrrroqDrsPGNm5c2ccnjlzZiJu2bJlqee3Z5v7Voco9cAGO/6CCy5IxNnv0T1HWrpyz58XtaxEJAiqrEQkCKqsRCQIdTVmtXjx4lpnQQJT6aoL7uoFTzzxRBx2pzUsWbIkDv/1r39NPaY7LlTpChC+8aV33nknEWf/3MYde7KP44tzaeqCiHRrqqxEJAiqrEQkCMzYv0wkqrQvXW31sCRMBp2zLGP3kVoQKi1P7pItr7zyShx+6KGHEnF2WnfZGd8DSCdNmhSHzz///EScO2Zmvw/3aUmDBw+Ow0eOHEnErV+/Pg7/7Gc/Sz2mOz/rtddei8OrVq1KxNljfW4+e/To4b3galmJSBBUWYlIEILvBto/H3j11VdT09U6nzlSNzBHxikYvoeV+lxzzTVx+Lvf/W4irrm5OQ63trYm4saOHRuH3a6er8zaXbZ///vfiTjfKqbjxo1LbO/evTsO//nPf07E2d3LQYMGJeLOPffcOOzme8+ePXF42LBhqXlzu8soUbbVshKRIKiyEpEgqLISkSAEP2aVdVyh1vnMkcasclTOmJXv63rfyqH2dAF7jAgARo0aFYcbGxtTz+euFHr48OE4vGHDhkScb8kWd5zInpIwZ86cRJw9zcDNmz3WdumllybiXnjhhTi8du3aRJz9nopcM41ZiUj4VFmJSBDqatUFn0OHDiW2+/fvX6OcSFfidvV8q3PafN0+1+bNm1PPZ89u9/HlxfeACAC49tprU+P27t0bh92VJOwVGY4dO5aIW7NmTdEwkL277Fvxohi1rEQkCKqsRCQIqqxEJAh1PXXB/rr16NGjnZGdzqCpCznyTV3wjROVM97iW3HTPoc7nuROV8jKzcs//vGPOPzRj340EXfRRRfFYXf8zM6PbzpEOdM47LSauiAidUmVlYgEocNTF+wFugBg9OjRHT1kbl5//fVaZ0G6ON/X/r4hDrfLZh/H1y1yu2j2fr4uoi+fvsX23O2WlpZE3L/+9S9k4XtPvm6fe518ixTaUyWK5qFkLkVEugBVViISBFVWIhKEDo9ZLV26NLF9++23d/SQXvfee2/mtIsWLYrD8+bNq0JuJHS+VTVdJb52T42zx2J84zS+OHcag30O9z3Yq3gCyRUSbrnllkScb8qF7z36pnjY42vuMey8lhqjcqllJSJBUGUlIkHo8Ax238Jb1fDYY48ltm+44YbUtBMnTozDL774YtXy1Mk0gz1H5cxgt5M2NDQk4uwVC9zuTZEHIxQ9Xzm/BvF1H13nnXdeHHYX6vN1J7PGuXxTLjSDXUTqniorEQmCKisRCUKHx6zelbDKqzDYDzUF/A82tT399NOJ7c9+9rO55amTacwqX6kF1vezlVqvNlIPilxDjVmJSPhUWYlIEILrBoq6gTlTN7BG1A0UkbqkykpEgqDKSkSCoMpKRIKgykpEgqDKSkSC0OHF90L17LPPJrYfeOCBOPzUU091dnYy01fm0l2pZSUiQVBlJSJBUGUlIkHI+nMbEZGaUstKRIKgykpEgqDKSkSCoMpKRIKgykpEgqDKSkSC8P8jashuihpt6AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIKvbu0mN2f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzA2W6MmN2lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_model=load_model('/content/drive/My Drive/Data_soduku/Digit_Model_P21.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-WZv4-jN2rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images_dir='/content/drive/My Drive/Data_soduku/Digits1/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxeY1u3tN2xY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images=os.listdir(images_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oq9tRsYN225",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a71e2ce3-a268-4126-a583-5083c46b99f6"
      },
      "source": [
        "predict_grid= np.zeros((9,9))\n",
        "\n",
        "for image in images:\n",
        "    imagec=image.split(\".\")[0][5:7]\n",
        "    (x,y)=(int(imagec[0]),int(imagec[1]))\n",
        "    my_image=cv2.imread(images_dir+image,0)\n",
        "    #print(images_dir+image)\n",
        "    my_image=cv2.resize(my_image,(28,28))\n",
        "    my_image=np.array(my_image)\n",
        "    my_image=my_image\n",
        "    my_image=my_image/255\n",
        "    my_image = np.expand_dims(my_image, axis=0)\n",
        "    my_image = np.expand_dims(my_image, axis=0)\n",
        "    my_image=my_image.reshape(1,28,28,1)\n",
        "    predict_grid[x][y] = new_model.predict_classes(my_image, verbose=0)[0]\n",
        "    \n",
        "    #org_img=cv2.imread(images_dir+image,1)\n",
        "\n",
        "print(predict_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 5. 0. 5. 7. 5. 0. 7.]\n",
            " [3. 0. 0. 0. 5. 0. 0. 7. 9.]\n",
            " [5. 0. 0. 0. 6. 5. 0. 0. 0.]\n",
            " [0. 5. 0. 0. 0. 5. 0. 6. 8.]\n",
            " [0. 6. 0. 3. 4. 0. 6. 0. 0.]\n",
            " [4. 0. 2. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 3. 4. 0. 0. 0. 1. 0. 0.]\n",
            " [8. 0. 0. 9. 0. 0. 0. 9. 1.]\n",
            " [0. 1. 1. 2. 1. 1. 2. 2. 9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WxY4JdHuzPxZ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}